{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "17m_h4uybM60tYO_JiMIosvOv3Wytwz9L",
      "authorship_tag": "ABX9TyPVd/BmWzz82Wwf36D4YrQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trian-ctrn/license-plate/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjy2gf04Tai8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "from datetime import datetime\n",
        "import random\n",
        "import PIL.ImageOps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCvNru8YWhfJ"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/charTrainset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpdMieVKaES4"
      },
      "source": [
        "### Check h√¨nh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIcId1-eZfNK"
      },
      "source": [
        "label = ['0','1','2','3','4','5','6','7','8','9',\n",
        "         'A','B','C','D','E','F','G','H','K','L','M','N','P','R','S','T','U','V','X','Y','Z']\n",
        "list_img = []\n",
        "for i in range(len(label)):\n",
        "  IMG_PATH = '/content/charTrainset/'+ label[i] \n",
        "  data_paths = [os.path.join(IMG_PATH, f) for f in os.listdir(IMG_PATH)]\n",
        "  img = [i for i in data_paths if os.path.isfile(i)]\n",
        "  list_img.append(img)\n",
        "print(list_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiTCL69BMRsU"
      },
      "source": [
        "plt.figure(figsize=(20,4))\n",
        "for i in range(10):\n",
        "  target = np.random.randint(0, len(list_img))\n",
        "\n",
        "  plt.subplot(2,5, i+1)\n",
        "  image = Image.open(list_img[target][3]).convert('L')\n",
        "  imgplot = plt.imshow(image)\n",
        "  title = 'Ground Truth: '\n",
        "  \n",
        "  for j in label[target]:       \n",
        "    title += j      \n",
        "  plt.title(title)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vLwgHF3Z7KI"
      },
      "source": [
        "### Image retraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U20MPRG0avds"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers.experimental.preprocessing import *\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.random import set_seed\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.applications import *\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOcBBL0ma-UU"
      },
      "source": [
        "def gray_to_rgb(img):\n",
        "    return np.repeat(img, 3, 2)\n",
        "\n",
        "datagen_kwargs = dict(validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=(224,224), \n",
        "                   interpolation=\"bilinear\")\n",
        "                   \n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    '/content/charTrainset', \n",
        "    subset=\"validation\", \n",
        "    shuffle=False,\n",
        "    color_mode ='grayscale', \n",
        "    **dataflow_kwargs\n",
        ")\n",
        "\n",
        "do_data_augmentation = False \n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rotation_range=10,\n",
        "      # horizontal_flip=True,\n",
        "      width_shift_range=0.2, height_shift_range=0.2,\n",
        "      # shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      **datagen_kwargs)\n",
        "else:\n",
        "  train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/charTrainset', \n",
        "    subset=\"training\", \n",
        "    shuffle=True,\n",
        "    color_mode ='grayscale', \n",
        "    **dataflow_kwargs\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimXCQDmEiE6"
      },
      "source": [
        "x = train_generator.next()\n",
        "image = x[0]\n",
        "image = tf.convert_to_tensor(image, dtype=tf.int8)\n",
        "converted = tf.image.grayscale_to_rgb(image[0])\n",
        "converted.numpy()\n",
        "plt.imshow(converted)\n",
        "# plt.imshow(np.squeeze(image[0]), cmap='gray')\n",
        "# max(image[0].astype(np.int8).flatten()), min(image[0].astype(np.int8).flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEi14d-Marav"
      },
      "source": [
        "### Mobilev2net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4at-H8Hoa2JV"
      },
      "source": [
        "base_model =  tf.keras.applications.MobileNetV2((224,224,3),include_top=False)\n",
        "base_model.trainable = False\n",
        "# Prediction layer\n",
        "prediction_layer = Dense(31,activation = 'softmax')\n",
        "#Preprocess input\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "# Global average layer\n",
        "global_average_layer = GlobalAveragePooling2D()\n",
        "# base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woWPSDGca3N_"
      },
      "source": [
        "inputs = Input(shape=(224,224,1))\n",
        "x = tf.image.grayscale_to_rgb(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x) \n",
        "model = Model(inputs,outputs)\n",
        "# model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(train_generator,epochs = 30, validation_data=valid_generator).history  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psO9RRCO4eDh"
      },
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk97BwozAjGu"
      },
      "source": [
        "def booyah4(url): \n",
        "  a = []\n",
        "  b = ''  \n",
        "  image = Image.open(url).convert('L')\n",
        "  image = PIL.ImageOps.invert(image)\n",
        "  newsize = (224,224)\n",
        "  width, height = image.size \n",
        "  top = 0  \n",
        "  bottom = height/2.05\n",
        "  left = width/7\n",
        "  right = width/3.9\n",
        "  image1 = image.crop((left, top, right, bottom))\n",
        "  image1 = image1.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image1, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = width/3.6\n",
        "  right = width/2.4\n",
        "  image2 = image.crop((left, top, right, bottom))\n",
        "  image2 = image2.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image2, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = width/1.65\n",
        "  right = width/1.35\n",
        "  image3 = image.crop((left, top, right, bottom))\n",
        "  image3 = image3.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image3, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = right\n",
        "  right = width/1.1\n",
        "  image4 = image.crop((left, top, right, bottom))\n",
        "  image4 = image4.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image4, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  top = height/2\n",
        "  bottom = height/1.05\n",
        "  left = width/8 \n",
        "  right = width/3.5\n",
        "  image5 = image.crop((left, top, right, bottom))\n",
        "  image5 = image5.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image5, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = width/3\n",
        "  right = width/2.1\n",
        "  image6 = image.crop((left, top, right, bottom))\n",
        "  image6 = image6.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image6, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = width/1.8\n",
        "  right = width/1.5\n",
        "  image7 = image.crop((left, top, right, bottom))\n",
        "  image7 = image7.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image7, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = width/1.35\n",
        "  right = width/1.15\n",
        "  image8 = image.crop((left, top, right, bottom))\n",
        "  image8 = image8.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image8, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "  b = 'Bi·ªÉn s·ªë xe trong h√¨nh l√†:'+a[0]+a[1]+'-'+a[2]+a[3]+' '+a[4]+a[5]+a[6]+a[7]\n",
        "  return b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfJM1hMFEyco"
      },
      "source": [
        "def booyah5(url):\n",
        "  a = []\n",
        "  b = ''\n",
        "  image = Image.open(url).convert('L')\n",
        "  image = PIL.ImageOps.invert(image)\n",
        "  newsize = (224,224)\n",
        "  width, height = image.size \n",
        "  top = 0\n",
        "  bottom = height/2.1\n",
        "  left = width/9\n",
        "  right = width/4\n",
        "  image1 = image.crop((left, top, right, bottom))\n",
        "  image1 = image1.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image1, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = right\n",
        "  right = width/2.7\n",
        "  image2 = image.crop((left, top, right, bottom))\n",
        "  image2 = image2.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image2, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "  \n",
        "  \n",
        "  left = width/1.62\n",
        "  right = width/1.4\n",
        "  image3 = image.crop((left, top, right, bottom))\n",
        "  image3 = image3.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image3, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = right\n",
        "  right = width/1.05\n",
        "  image4 = image.crop((left, top, right, bottom))\n",
        "  image4 = image4.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image4, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  top = bottom\n",
        "  bottom = height/1.05\n",
        "  left = width/11\n",
        "  right = width/5.5\n",
        "  image5 = image.crop((left, top, right, bottom))\n",
        "  image5 = image5.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image5, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = width/4\n",
        "  right = width/2.9\n",
        "  image6 = image.crop((left, top, right, bottom))\n",
        "  image6 = image6.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image6, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = width/2.7\n",
        "  right = width/2\n",
        "  image7 = image.crop((left, top, right, bottom))\n",
        "  image7 = image7.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image7, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = width/1.6\n",
        "  right = width/1.35\n",
        "  image8 = image.crop((left, top, right, bottom))\n",
        "  image8 = image8.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image8, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "\n",
        "  left = width/1.22\n",
        "  right = width/1.1\n",
        "  image9 = image.crop((left, top, right, bottom))\n",
        "  image9 = image9.resize(newsize)\n",
        "  prediction_scores = model.predict(np.expand_dims(image9, axis=0))\n",
        "  predicted_index = np.argmax(prediction_scores)\n",
        "  a.append(label[predicted_index])\n",
        "  b = 'Bi·ªÉn s·ªë xe trong h√¨nh l√†:'+a[0]+a[1]+'-'+a[2]+a[3]+' '+a[4]+a[5]+a[6]+'.'+a[7]+a[8]\n",
        "  return b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j0-V7tiTgQ1"
      },
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRQ-z6VKNgI8"
      },
      "source": [
        "name_dict = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb1czMbkVHmN"
      },
      "source": [
        "\n",
        "def get_value(name):\n",
        "    for key, value in name_dict.items():\n",
        "        if name == key:\n",
        "          return value\n",
        "    return 'Welcome'\n",
        "\n",
        "def new(name,name_dict,choose,url):\n",
        "  id = random.randint(100000, 1000000)\n",
        "  time =  str(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "  if choose == 'Bi·ªÉn 5 Ch·ªØ':\n",
        "    name_dict[name] = [id,time,booyah5(url)]\n",
        "    return name_dict\n",
        "  elif choose == 'Bi·ªÉn 4 Ch·ªØ':\n",
        "    name_dict[name] = [id,time,booyah4(url)]\n",
        "    return name_dict\n",
        "\n",
        "def get_minutes(name):\n",
        "  fmt = '%Y-%m-%d %H:%M:%S'\n",
        "  outtime = str(datetime.now().strftime(fmt))\n",
        "  d2 = datetime.strptime(outtime, fmt)\n",
        "  intime = get_value(name)[1]\n",
        "  d1 = datetime.strptime(intime, fmt)\n",
        "  minutes_diff = (d2-d1).total_seconds() / 60.0\n",
        "  return minutes_diff\n",
        "\n",
        "def total_money(name,minutes_diff):\n",
        "  if minutes_diff < 30:\n",
        "        del name_dict[name]\n",
        "        return '0 VND'\n",
        "  elif minutes_diff < 120:\n",
        "        del name_dict[name]\n",
        "        return '2000 VND'\n",
        "  elif minutes_diff < 300:\n",
        "        del name_dict[name]\n",
        "        return '5000 VND'\n",
        "  else:\n",
        "        a = '{} VND'.format(5000 + minutes_diff*10)\n",
        "        del name_dict[name]\n",
        "        return a\n",
        "def greet(name,choose,url):\n",
        "  if name in list(name_dict.keys()) :\n",
        "    if choose == 'Bi·ªÉn 5 Ch·ªØ':\n",
        "      if get_value(name)[2] == booyah5(url):\n",
        "        minutes_diff = get_minutes(name)\n",
        "        total = total_money(name,minutes_diff)\n",
        "        return booyah5(url),total\n",
        "      else:\n",
        "        return 'This name is picked already','Haizz'\n",
        "    elif choose == 'Bi·ªÉn 4 Ch·ªØ':\n",
        "      if get_value(name)[2] == booyah4(url):\n",
        "        minutes_diff = get_minutes(name)\n",
        "        total = total_money(name,minutes_diff)\n",
        "        return booyah4(url),total\n",
        "      else:\n",
        "        return 'This name is picked already','Haizz'\n",
        "  else:\n",
        "    if choose == 'Bi·ªÉn 5 Ch·ªØ':\n",
        "      huhu = new(name,name_dict,choose,url)\n",
        "      return booyah5(url),None\n",
        "    if choose == 'Bi·ªÉn 4 Ch·ªØ':\n",
        "      huhu = new(name,name_dict,choose,url)\n",
        "      return booyah4(url),None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzj9ZtVbJyEh"
      },
      "source": [
        "#Demo th·ª≠ t·∫°i ch·ªó lu√¥n\n",
        "\n",
        "print(name_dict)\n",
        "print(greet('An','Bi·ªÉn 4 Ch·ªØ','/content/drive/MyDrive/biensoxe2.jpg'))\n",
        "print(name_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWTqYHMwz4wY"
      },
      "source": [
        "# H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng nh√¨n bi·ªÉn s·ªë xe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95WNI7Wl0B8S"
      },
      "source": [
        "1. Khi ch·∫°y d√≤ng code ·ªü d∆∞·ªõi ƒë·∫ßu ti√™n l√† nh·∫≠p t√™n c·ªßa m√¨nh. C√≥ th·ªÉ kh√¥ng c·∫ßn nh·∫≠p \n",
        "2. Ch·ªçn c√°c lo·∫°i bi·ªÉn s·ªë xe, d∆∞·ªõi ƒë√¢y s·∫Ω l√† c√°c v√¨ d·ª• v·ªÅ c√°c lo·∫°i bi·ªÉn s·ªë xe\n",
        "- Bi·ªÉn 4 ch·ªØ (l√† bi·∫øn s·ªë g·ªìm c√≥ 4 ch·ªØ ·ªü d∆∞·ªõi c√πng): ![](https://cdn.discordapp.com/attachments/788768348569600031/842396971217846302/image0.jpg)\n",
        "- Bi·ªÉn 5 ch·ªØ (l√† bi·ªÉn s·ªë g·ªìm c√≥ 5 ch·ªØ s·ªë ·ªü d∆∞·ªõi c√πng): ![](https://baodansinh.mediacdn.vn/Images/2016/06/07/tranhuyenbtv/20131907204552.jpg)\n",
        "- Bi·ªÉn ƒë·∫∑c bi·ªát (l√† bi·ªÉn bao g·ªìm 2 ch·ªØ c√°i)\n",
        "3. Nh·∫≠p t√™n ƒë·ªôc v√† l·∫° ƒë·ªÉ tr√°nh tr∆∞·ªùng h·ª£p b·ªã tr√πng t√™n\n",
        "4. L∆∞u √Ω gi√° ti·ªÅn xe s·∫Ω ph·ª• thu·ªôc v√†o th·ªùi gian: d∆∞·ªõi 30 ph√∫t th√¨ ƒë∆∞·ª£c free, d∆∞·ªõi 2 ti·∫øng th√¨ tr·∫£ 2000VND, d∆∞·ªõi 5 ti·∫øng th√¨ tr·∫£ 5000VND c·ª© sau 5 ti·∫øng th√¨ 5000VND c·ªông t·ªïng s·ªë ph√∫t gi·ªØ xe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilNrCKs0V1bT"
      },
      "source": [
        "iface = gr.Interface(fn=greet, \n",
        "                     inputs = ['text',gr.inputs.Dropdown([\"Bi·ªÉn 4 Ch·ªØ\", \"Bi·ªÉn 5 Ch·ªØ\"]),'text'],\n",
        "                     outputs=[gr.outputs.Textbox(label='Bi·ªÉn: '),gr.outputs.Textbox(label='Ti·ªÅn: ')]\n",
        "                     )\n",
        "iface.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLFioF-UHjVV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}